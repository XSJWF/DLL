{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 卷积神经网络\n",
    "## 全连接层-卷积\n",
    "### 不变性\n",
    "- **平移不变性**：不管检测对象出现在图像中的哪个位置，神经网络的前面几层\n",
    "应该对相同的图像区域具有相似的反应，即为“平移不变性”。\n",
    "- **局部性**：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。\n",
    "### 多层感知机的限制\n",
    "- 参数量巨大。\n",
    "- 空间信息丢失（因为输入模型前会强行拉伸为一个一维向量）。\n",
    "- 输入尺寸固定。\n",
    "### 卷积\n",
    "- 卷积核（矩阵）滑动进行一个点乘求和的过程，最终得到一个新的矩阵（张量，特征图）。\n",
    "## 图像卷积\n",
    "- 说是卷积其实也就是一个互相关运算。\n"
   ],
   "id": "23b18647806fcf88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:05.750719Z",
     "start_time": "2025-08-26T03:19:05.739036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "\"\"\"测试代码\"\"\"\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "result = corr2d(X, K)\n",
    "print(result)"
   ],
   "id": "3716dce0783e4b62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19., 25.],\n",
      "        [37., 43.]])\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 卷积层构造",
   "id": "ce29b4faee65fa52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:06.975242Z",
     "start_time": "2025-08-26T03:19:06.968023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.corr2d(x, self.weight) + self.bias\n",
    "    \n",
    "    @staticmethod\n",
    "    def corr2d(X, K):\n",
    "        h, w = K.shape\n",
    "        Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "        for i in range(Y.shape[0]):\n",
    "            for j in range(Y.shape[1]):\n",
    "                Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "        return Y"
   ],
   "id": "b32b9cbf65f6e658",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 图像中的目标边缘检测\n",
    "- 黑白边缘检测（只需要一维简单的卷积核）"
   ],
   "id": "9e40028f1fc65694"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:08.369979Z",
     "start_time": "2025-08-26T03:19:08.361737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ],
   "id": "67971fec683a153b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:09.002016Z",
     "start_time": "2025-08-26T03:19:08.994665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "K = np.array([[1, -1]])\n",
    "K"
   ],
   "id": "44dbd54cfb68d908",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:09.743855Z",
     "start_time": "2025-08-26T03:19:09.731336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ],
   "id": "b891ef177f980f76",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:10.411709Z",
     "start_time": "2025-08-26T03:19:10.400601Z"
    }
   },
   "cell_type": "code",
   "source": "corr2d(torch.transpose(X, 0, 1), K)  # 转置",
   "id": "3564108f2d30679",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 二维卷积层",
   "id": "201e8f5aa1d82d0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:11.782048Z",
     "start_time": "2025-08-26T03:19:11.764895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "X = X.reshape(1, 1, 6, 8)\n",
    "Y = Y.reshape(1, 1, 6, 7)\n",
    "\n",
    "lr = 3e-2\n",
    "\n",
    "optimizer = torch.optim.SGD(conv2d.parameters(), lr=lr)\n",
    "\n",
    "for i in range(10):\n",
    "    \"\"\"前向传播\"\"\"\n",
    "    Y_hat= conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    \n",
    "    \"\"\"反向传播\"\"\"\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    \n",
    "    # \"\"\"手动更新权重\"\"\"\n",
    "    # with torch.no_grad():\n",
    "    #     conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    \n",
    "    optimizer.step()    \n",
    "    \n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i + 1}, loss {l.sum().detach().item():.3f}')"
   ],
   "id": "656a031cd66d0a02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 8.847\n",
      "epoch 4, loss 1.507\n",
      "epoch 6, loss 0.262\n",
      "epoch 8, loss 0.048\n",
      "epoch 10, loss 0.010\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:12.577550Z",
     "start_time": "2025-08-26T03:19:12.571069Z"
    }
   },
   "cell_type": "code",
   "source": "conv2d.weight.data.reshape((1, 2))",
   "id": "6c4b54301019e681",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9899, -0.9793]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**注**：在 $\\mathrm{CNN}$ 中卷积运算和互相关运算的效果差不多，但后者更方便，但是在数学中的含义是不同的。\n",
    "### 特征映射和感受野\n",
    "- 特征映射就是输出的卷积层。\n",
    "- 感受野就是特征矩阵每次被卷积核覆盖的那一部分。\n",
    "## 填充和步幅\n",
    "### 填充\n",
    "- 就是为了保持特征图（空间）的维度（可以联系放大缩小图片来简单理解一下）。\n",
    "- 保护边界信息（边缘信息在没有填充的情况下参与计算的次数比其他位置的信息少）。"
   ],
   "id": "e1c39ab8117ac2f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:14.072055Z",
     "start_time": "2025-08-26T03:19:14.062519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n",
    "X = torch.from_numpy(np.random.uniform(size=(8, 8))).float()\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "id": "e2ef60c8f710bf6c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:14.867756Z",
     "start_time": "2025-08-26T03:19:14.859746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "id": "57bbca07cb654819",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 步幅\n",
    "- 就是卷积核一次移动的行、列数（分别对应水平、垂直步幅）。"
   ],
   "id": "1a2b8b29d4d9579"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:16.293044Z",
     "start_time": "2025-08-26T03:19:16.286534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "id": "d3659393e6f79e18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:17.031162Z",
     "start_time": "2025-08-26T03:19:17.024640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "id": "8d94386ef50ab0b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 多输入多通道\n",
    "### 多输入通道"
   ],
   "id": "cce0ca74cf7059f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:18.430077Z",
     "start_time": "2025-08-26T03:19:18.421561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def corr2d_multi_in_pytorch(X, K):\n",
    "    X = X.unsqueeze(0)\n",
    "    K = K.unsqueeze(0)\n",
    "    \n",
    "    output = torch.nn.functional.conv2d(X, K)\n",
    "    \n",
    "    return output.squeeze(0)\n",
    "\n",
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]], [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "corr2d_multi_in_pytorch(X, K)"
   ],
   "id": "a8595089a64c4cc3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 多输出通道",
   "id": "10ccab68100cac4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:19.710218Z",
     "start_time": "2025-08-26T03:19:19.703810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def corr2d_multi_out_pytorch(X, K):\n",
    "    \"\"\"使用PyTorch内置函数实现多输入多输出通道互相关\"\"\"\n",
    "    X = X.unsqueeze(0)\n",
    "    output = torch.nn.functional.conv2d(X, K)\n",
    "    return output.squeeze(0)\n",
    "\n",
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ],
   "id": "5761f8cdcd94ce5e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:20.368350Z",
     "start_time": "2025-08-26T03:19:20.360838Z"
    }
   },
   "cell_type": "code",
   "source": "corr2d_multi_out_pytorch(X, K)",
   "id": "f5fe714944063f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1 $\\times$ 1卷积层",
   "id": "e91d19c589c31cdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:21.583254Z",
     "start_time": "2025-08-26T03:19:21.577249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    \n",
    "    Y = torch.mm(K, X)  # 使用torch.mm进行矩阵乘法\n",
    "    return Y.reshape((c_o, h, w))"
   ],
   "id": "c0aa8ebefb1d27f4",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:22.151372Z",
     "start_time": "2025-08-26T03:19:22.146337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.randn(3, 3, 3)\n",
    "K = torch.randn(2, 3, 1, 1)"
   ],
   "id": "a7877aad57abd3fa",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:22.623766Z",
     "start_time": "2025-08-26T03:19:22.614878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_out_pytorch(X, K)\n",
    "assert float(np.abs(Y1 - Y2).sum()) < 1e-6\n",
    "print(Y1,\"\\n\",Y2)"
   ],
   "id": "c5b4e0007ee738cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.9549,  0.5617, -1.0108],\n",
      "         [ 0.7516, -0.3996, -1.0445],\n",
      "         [ 0.9544, -1.9995, -2.2511]],\n",
      "\n",
      "        [[ 2.7576,  2.0785, -1.1758],\n",
      "         [ 0.9664, -1.1479, -0.3568],\n",
      "         [ 0.7093, -3.3872, -2.6560]]]) \n",
      " tensor([[[ 1.9549,  0.5617, -1.0108],\n",
      "         [ 0.7516, -0.3996, -1.0445],\n",
      "         [ 0.9544, -1.9995, -2.2511]],\n",
      "\n",
      "        [[ 2.7576,  2.0785, -1.1758],\n",
      "         [ 0.9664, -1.1479, -0.3568],\n",
      "         [ 0.7093, -3.3872, -2.6560]]])\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 汇聚（池化）层\n",
    "- 对卷积层输出的特征图进行降维压缩，从而提炼和浓缩信息（就是划一个窗口里面计算选一个值来代替）。\n",
    "### 最大汇聚（池化）层\n",
    "- 选择窗口中的最大值。\n",
    "### 平均汇聚（池化）层\n",
    "- 计算窗口中的平均值。"
   ],
   "id": "780f1cbcf7ae84ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:23.930505Z",
     "start_time": "2025-08-26T03:19:23.921665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y\n",
    "\n",
    "X = np.array([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ],
   "id": "f284bf55f71cddc7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:24.717414Z",
     "start_time": "2025-08-26T03:19:24.709898Z"
    }
   },
   "cell_type": "code",
   "source": "pool2d(X, (2, 2), 'avg')",
   "id": "304ad4113dd91d5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 填充和步幅\n",
    "- 和卷积里面的含义差不多。"
   ],
   "id": "67f89a038b5bb4c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:26.029208Z",
     "start_time": "2025-08-26T03:19:26.021710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = np.arange(16, dtype=np.float32).reshape(1, 1, 4, 4)\n",
    "X"
   ],
   "id": "5844892af38a3c89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.]]]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:26.616957Z",
     "start_time": "2025-08-26T03:19:26.607909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(torch.from_numpy(X))"
   ],
   "id": "c294e4b4fbb6eefd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:27.233124Z",
     "start_time": "2025-08-26T03:19:27.226718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(torch.from_numpy(X))"
   ],
   "id": "1ed2a45c8b7ee8aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:27.764616Z",
     "start_time": "2025-08-26T03:19:27.758447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool2d = nn.MaxPool2d((2, 3), padding=(0, 1), stride=(2, 3))\n",
    "pool2d(torch.from_numpy(X))"
   ],
   "id": "1208728a19b74f4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 多个通道\n",
    "- 也是类似卷积里面的多通道。"
   ],
   "id": "95ad67742e67f3f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:29.177618Z",
     "start_time": "2025-08-26T03:19:29.172141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = np.concatenate((X, X + 1), 1)\n",
    "X"
   ],
   "id": "3eb5b7aa38e31173",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.]],\n",
       "\n",
       "        [[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.],\n",
       "         [13., 14., 15., 16.]]]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:29.863288Z",
     "start_time": "2025-08-26T03:19:29.856356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(torch.from_numpy(X))"
   ],
   "id": "281c7b4f2f45485b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 卷积神经网络\n",
    "![卷积神经网络](../image/ConvolutionalNeuralNetworks.jpg)"
   ],
   "id": "201e137c51d87c7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:31.604575Z",
     "start_time": "2025-08-26T03:19:31.591218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LaNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LaNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 先进行一次前向传播来计算特征数\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 1, 28, 28)\n",
    "            dummy_output = self.features(dummy_input)\n",
    "            self.num_features = dummy_output.numel() // dummy_output.shape[0]  # 除batch_size\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.num_features, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "net = LaNet()\n",
    "\n",
    "print(net)"
   ],
   "id": "23cd5a9ba4d0f77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LaNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Sigmoid()\n",
      "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (4): Sigmoid()\n",
      "    (5): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:32.635618Z",
     "start_time": "2025-08-26T03:19:32.627716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.rand(size=(1, 1, 28, 28))\n",
    "\n",
    "for name, layer in net.named_children():\n",
    "    if name == 'features' or name == 'classifier':\n",
    "        print(f\"\\n==={name}===\")\n",
    "        for sub_name, sub_layer in layer.named_children():\n",
    "            X = sub_layer(X)\n",
    "            print(f'{sub_name}: {type(sub_layer).__name__} output shape:\\t{X.shape}')   \n",
    "    else:\n",
    "        X = layer(X)\n",
    "        print(f'{name}: {type(layer).__name__} output shape:\\t{X.shape}')"
   ],
   "id": "b636b22fdbee742e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===features===\n",
      "0: Conv2d output shape:\ttorch.Size([1, 6, 28, 28])\n",
      "1: Sigmoid output shape:\ttorch.Size([1, 6, 28, 28])\n",
      "2: AvgPool2d output shape:\ttorch.Size([1, 6, 14, 14])\n",
      "3: Conv2d output shape:\ttorch.Size([1, 16, 10, 10])\n",
      "4: Sigmoid output shape:\ttorch.Size([1, 16, 10, 10])\n",
      "5: AvgPool2d output shape:\ttorch.Size([1, 16, 5, 5])\n",
      "\n",
      "===classifier===\n",
      "0: Flatten output shape:\ttorch.Size([1, 400])\n",
      "1: Linear output shape:\ttorch.Size([1, 120])\n",
      "2: Sigmoid output shape:\ttorch.Size([1, 120])\n",
      "3: Linear output shape:\ttorch.Size([1, 84])\n",
      "4: Sigmoid output shape:\ttorch.Size([1, 84])\n",
      "5: Linear output shape:\ttorch.Size([1, 10])\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:19:33.382952Z",
     "start_time": "2025-08-26T03:19:33.372094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"使用Sequential构建网络\"\"\"\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2),\n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5),\n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")\n",
    "\n",
    "\"\"\"生成随机输入\"\"\"\n",
    "X = torch.rand(size=(1, 1, 28, 28))\n",
    "print(\"输入形状:\", X.shape)\n",
    "\n",
    "\"\"\"遍历每一层并打印输出形状\"\"\"\n",
    "for i, layer in enumerate(net):\n",
    "    X = layer(X)\n",
    "    print(f'Layer {i}: {layer.__class__.__name__} output shape:\\t{X.shape}')"
   ],
   "id": "85f0cba7fadb745b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入形状: torch.Size([1, 1, 28, 28])\n",
      "Layer 0: Conv2d output shape:\ttorch.Size([1, 6, 28, 28])\n",
      "Layer 1: Sigmoid output shape:\ttorch.Size([1, 6, 28, 28])\n",
      "Layer 2: AvgPool2d output shape:\ttorch.Size([1, 6, 14, 14])\n",
      "Layer 3: Conv2d output shape:\ttorch.Size([1, 16, 10, 10])\n",
      "Layer 4: Sigmoid output shape:\ttorch.Size([1, 16, 10, 10])\n",
      "Layer 5: AvgPool2d output shape:\ttorch.Size([1, 16, 5, 5])\n",
      "Layer 6: Flatten output shape:\ttorch.Size([1, 400])\n",
      "Layer 7: Linear output shape:\ttorch.Size([1, 120])\n",
      "Layer 8: Sigmoid output shape:\ttorch.Size([1, 120])\n",
      "Layer 9: Linear output shape:\ttorch.Size([1, 84])\n",
      "Layer 10: Sigmoid output shape:\ttorch.Size([1, 84])\n",
      "Layer 11: Linear output shape:\ttorch.Size([1, 10])\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T03:42:35.752804Z",
     "start_time": "2025-08-26T03:19:34.234495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将PIL图像转换为Tensor，并归一化到[0,1]\n",
    "])\n",
    "\n",
    "# 加载训练集和测试集\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "train_iter = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,  # 训练集需要打乱\n",
    "    num_workers=2  # 使用多进程加载数据\n",
    ")\n",
    "\n",
    "test_iter = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,  # 测试集不需要打乱\n",
    "    num_workers=2\n",
    ")"
   ],
   "id": "296d887f933970c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [19:35<00:00, 22.5kB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 40.4kB/s]\n",
      "100%|██████████| 4.42M/4.42M [02:45<00:00, 26.7kB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 5.15MB/s]\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T05:04:04.755478Z",
     "start_time": "2025-08-26T05:04:04.745755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    if device is None:\n",
    "        device = next(net.parameters().device if list(net.parameters()) else torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            outputs = net(X)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "    return correct / total"
   ],
   "id": "8a8e67f26b5d1cdc",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T05:37:11.863056Z",
     "start_time": "2025-08-26T05:37:11.838522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"简单的计时器类\"\"\"\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"启动计时器\"\"\"\n",
    "        self.tik = time.time()\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"停止计时器并记录时间\"\"\"\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "    \n",
    "    def avg(self):\n",
    "        \"\"\"返回平均时间\"\"\"\n",
    "        return sum(self.times) / len(self.times)\n",
    "    \n",
    "    def sum(self):\n",
    "        \"\"\"返回时间总和\"\"\"\n",
    "        return sum(self.times)\n",
    "    \n",
    "    def cumsum(self):\n",
    "        \"\"\"返回累计时间\"\"\"\n",
    "        return torch.tensor(self.times).cumsum(dim=0).tolist()\n",
    "\n",
    "class Accumulator:\n",
    "    \"\"\"用于累加多个变量的类\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "    \n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "def train_cnn_t(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"GPU训练\"\"\"\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "                \n",
    "    net.apply(init_weights)\n",
    "    net.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    \n",
    "    timer = Timer()\n",
    "    num_batches = len(train_iter)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(3)\n",
    "        net.train()\n",
    "        \n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = net(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                acc = accuracy(y_hat, y)\n",
    "                metric.add(loss.item() * X.shape[0], acc, X.shape[0])\n",
    "                \n",
    "            timer.stop()\n",
    "            \n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                train_l = metric[0] / metric[2]\n",
    "                train_acc = metric[1] / metric[2]\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}],'\n",
    "                      f'Step [{i+1}/{num_batches}],'\n",
    "                      f'Loss: {train_l:.3f},'\n",
    "                      f'Acc: {train_acc:.3f}')\n",
    "                \n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter, device)\n",
    "        train_l = metric[0] / metric[2]\n",
    "        train_acc = metric[1] / metric[2]\n",
    "        \n",
    "        train_losses.append(train_l)\n",
    "        train_accs.append(train_acc)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_l:.3f}, '\n",
    "              f'Train Acc: {train_acc:.3f}, '\n",
    "              f'Test Acc: {test_acc:.3f}')\n",
    "        \n",
    "    \"\"\"计算训练速度\"\"\"\n",
    "    total_examples = metric[2] * num_epochs\n",
    "    total_time = timer.sum()\n",
    "    speed = total_examples / total_time\n",
    "    \n",
    "    print(f'{speed:.1f} examples/sec on {device}')\n",
    "    \n",
    "    return train_losses, train_accs, test_accs"
   ],
   "id": "d173bf8e56b44254",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-26T05:41:05.281718Z",
     "start_time": "2025-08-26T05:38:05.688474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def try_gpu(i=0):\n",
    "    \"\"\"如果存在GPU，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "# 设置超参数\n",
    "lr, num_epochs = 0.9, 10\n",
    "\n",
    "# 调用训练函数\n",
    "train_cnn_t(net, train_iter, test_iter, num_epochs, lr, try_gpu())"
   ],
   "id": "acd4401edc7e0fe6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10],Step [47/235],Loss: 2.372,Acc: 0.100\n",
      "Epoch [1/10],Step [94/235],Loss: 2.343,Acc: 0.099\n",
      "Epoch [1/10],Step [141/235],Loss: 2.331,Acc: 0.103\n",
      "Epoch [1/10],Step [188/235],Loss: 2.322,Acc: 0.105\n",
      "Epoch [1/10],Step [235/235],Loss: 2.273,Acc: 0.130\n",
      "Epoch [1/10], Train Loss: 2.273, Train Acc: 0.130, Test Acc: 0.306\n",
      "Epoch [2/10],Step [47/235],Loss: 1.448,Acc: 0.427\n",
      "Epoch [2/10],Step [94/235],Loss: 1.313,Acc: 0.473\n",
      "Epoch [2/10],Step [141/235],Loss: 1.225,Acc: 0.508\n",
      "Epoch [2/10],Step [188/235],Loss: 1.161,Acc: 0.532\n",
      "Epoch [2/10],Step [235/235],Loss: 1.115,Acc: 0.550\n",
      "Epoch [2/10], Train Loss: 1.115, Train Acc: 0.550, Test Acc: 0.606\n",
      "Epoch [3/10],Step [47/235],Loss: 0.894,Acc: 0.644\n",
      "Epoch [3/10],Step [94/235],Loss: 0.878,Acc: 0.652\n",
      "Epoch [3/10],Step [141/235],Loss: 0.863,Acc: 0.658\n",
      "Epoch [3/10],Step [188/235],Loss: 0.841,Acc: 0.669\n",
      "Epoch [3/10],Step [235/235],Loss: 0.828,Acc: 0.674\n",
      "Epoch [3/10], Train Loss: 0.828, Train Acc: 0.674, Test Acc: 0.683\n",
      "Epoch [4/10],Step [47/235],Loss: 0.722,Acc: 0.720\n",
      "Epoch [4/10],Step [94/235],Loss: 0.723,Acc: 0.716\n",
      "Epoch [4/10],Step [141/235],Loss: 0.721,Acc: 0.717\n",
      "Epoch [4/10],Step [188/235],Loss: 0.708,Acc: 0.722\n",
      "Epoch [4/10],Step [235/235],Loss: 0.706,Acc: 0.723\n",
      "Epoch [4/10], Train Loss: 0.706, Train Acc: 0.723, Test Acc: 0.726\n",
      "Epoch [5/10],Step [47/235],Loss: 0.657,Acc: 0.745\n",
      "Epoch [5/10],Step [94/235],Loss: 0.658,Acc: 0.743\n",
      "Epoch [5/10],Step [141/235],Loss: 0.652,Acc: 0.746\n",
      "Epoch [5/10],Step [188/235],Loss: 0.644,Acc: 0.749\n",
      "Epoch [5/10],Step [235/235],Loss: 0.638,Acc: 0.752\n",
      "Epoch [5/10], Train Loss: 0.638, Train Acc: 0.752, Test Acc: 0.749\n",
      "Epoch [6/10],Step [47/235],Loss: 0.603,Acc: 0.767\n",
      "Epoch [6/10],Step [94/235],Loss: 0.606,Acc: 0.766\n",
      "Epoch [6/10],Step [141/235],Loss: 0.596,Acc: 0.768\n",
      "Epoch [6/10],Step [188/235],Loss: 0.595,Acc: 0.769\n",
      "Epoch [6/10],Step [235/235],Loss: 0.591,Acc: 0.770\n",
      "Epoch [6/10], Train Loss: 0.591, Train Acc: 0.770, Test Acc: 0.755\n",
      "Epoch [7/10],Step [47/235],Loss: 0.565,Acc: 0.784\n",
      "Epoch [7/10],Step [94/235],Loss: 0.565,Acc: 0.783\n",
      "Epoch [7/10],Step [141/235],Loss: 0.561,Acc: 0.782\n",
      "Epoch [7/10],Step [188/235],Loss: 0.554,Acc: 0.786\n",
      "Epoch [7/10],Step [235/235],Loss: 0.551,Acc: 0.787\n",
      "Epoch [7/10], Train Loss: 0.551, Train Acc: 0.787, Test Acc: 0.781\n",
      "Epoch [8/10],Step [47/235],Loss: 0.535,Acc: 0.791\n",
      "Epoch [8/10],Step [94/235],Loss: 0.532,Acc: 0.796\n",
      "Epoch [8/10],Step [141/235],Loss: 0.524,Acc: 0.798\n",
      "Epoch [8/10],Step [188/235],Loss: 0.521,Acc: 0.800\n",
      "Epoch [8/10],Step [235/235],Loss: 0.517,Acc: 0.802\n",
      "Epoch [8/10], Train Loss: 0.517, Train Acc: 0.802, Test Acc: 0.764\n",
      "Epoch [9/10],Step [47/235],Loss: 0.505,Acc: 0.808\n",
      "Epoch [9/10],Step [94/235],Loss: 0.499,Acc: 0.810\n",
      "Epoch [9/10],Step [141/235],Loss: 0.495,Acc: 0.813\n",
      "Epoch [9/10],Step [188/235],Loss: 0.489,Acc: 0.815\n",
      "Epoch [9/10],Step [235/235],Loss: 0.489,Acc: 0.815\n",
      "Epoch [9/10], Train Loss: 0.489, Train Acc: 0.815, Test Acc: 0.791\n",
      "Epoch [10/10],Step [47/235],Loss: 0.477,Acc: 0.817\n",
      "Epoch [10/10],Step [94/235],Loss: 0.476,Acc: 0.819\n",
      "Epoch [10/10],Step [141/235],Loss: 0.472,Acc: 0.821\n",
      "Epoch [10/10],Step [188/235],Loss: 0.472,Acc: 0.821\n",
      "Epoch [10/10],Step [235/235],Loss: 0.467,Acc: 0.824\n",
      "Epoch [10/10], Train Loss: 0.467, Train Acc: 0.824, Test Acc: 0.809\n",
      "38039.5 examples/sec on cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.2733701802571615,\n",
       "  1.115173760732015,\n",
       "  0.828308590221405,\n",
       "  0.705748969300588,\n",
       "  0.6375064541180928,\n",
       "  0.5908440706888834,\n",
       "  0.5505581643422445,\n",
       "  0.517240756225586,\n",
       "  0.4893931660016378,\n",
       "  0.4670578139781952],\n",
       " [0.13031666666666666,\n",
       "  0.5502833333333333,\n",
       "  0.6736166666666666,\n",
       "  0.7230333333333333,\n",
       "  0.7521333333333333,\n",
       "  0.7704833333333333,\n",
       "  0.78745,\n",
       "  0.8019,\n",
       "  0.8149166666666666,\n",
       "  0.8240166666666666],\n",
       " [0.3064,\n",
       "  0.6059,\n",
       "  0.6829,\n",
       "  0.7259,\n",
       "  0.7489,\n",
       "  0.7546,\n",
       "  0.7815,\n",
       "  0.764,\n",
       "  0.7909,\n",
       "  0.8094])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "629ebbf500e1f030"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
