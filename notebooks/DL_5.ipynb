{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 深度学习计算\n",
    "## 层和块\n",
    "- **块**可以描述单个层、由多个层组成的组件或整个模型本身：\n",
    "![多层网络组合成块图](../image/多层网络组合成块.jpg)\n",
    "- 块由类表示。它的任何子类都必须定义一个将其输入转换为输出的前向传播函数，并且必须存储任何必需的参数（有些块不需要任何参数），最后，为了计算梯度，块必须具有反向传播函数。"
   ],
   "id": "3ad9e6287d89c30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:29:43.030759Z",
     "start_time": "2025-07-26T02:29:37.737804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义网络结构\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(20, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "# 初始化权重（kaiming均匀初始化，这是PyTorch默认的初始化方法，比较适合relu函数，一般不需要手动写，这里只是第一次了解适应一下，一般PyTorch的神经网络层会自动初始化权重和偏置）\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias) # 默认偏置初始化为0\n",
    "\n",
    "net.apply(init_weights)\n",
    "\n",
    "# 生成输入数据\n",
    "X = torch.empty(2, 20).uniform_() # empty生成的是随机张量，uniform可以直接修改为均匀分布的随机数\n",
    "\n",
    "# 前向计算\n",
    "print(net(X))"
   ],
   "id": "15aa22cb8e6c27dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0488,  0.5612,  0.9806,  0.3183,  1.1335, -0.5094, -1.4717, -0.3531,\n",
      "         -0.0933, -0.8531],\n",
      "        [ 0.2146,  0.5187,  0.5918, -0.0031,  1.4823,  0.8675, -1.0937,  0.7217,\n",
      "         -0.3026,  0.0085]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 自定义块\n",
    "- 必须要实现的一些功能：\n",
    "    - 将输入数据作为其前向传播函数的参数；\n",
    "    - 通过前向传播函数来生成输出（输入输出的形状根据实际设置）；\n",
    "    - 计算其输出关于输入的梯度，可通过其反向传播函数进行访问（继承了 $\\mathrm{PyTorch}$ 的模型的话，这个过程可以自动实现）；\n",
    "    - 存储和访问前向传播计算所需的参数（继承了 $\\mathrm{PyTorch}$ 的模型的话，这个也不需要手动实现）；\n",
    "    - 自行初始化模型参数；"
   ],
   "id": "27bc3fa66dfa9450"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:06.229364Z",
     "start_time": "2025-07-26T02:30:06.224867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    # 自定义初始化声明神经网络层\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs) # 继承一下父类，可以省去一些函数代码的重新实现\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.hidden(X)\n",
    "        X = self.relu(X)\n",
    "        return self.out(X)"
   ],
   "id": "18cb94aa535fb5ad",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:06.743423Z",
     "start_time": "2025-07-26T02:30:06.734396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = MLP()\n",
    "net(X)"
   ],
   "id": "e34b8cfca78d3107",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0469,  0.2463,  0.0863, -0.1826,  0.1999, -0.0834, -0.0234,  0.2893,\n",
       "         -0.0872,  0.1544],\n",
       "        [-0.0553,  0.3012,  0.0235, -0.2252,  0.1415, -0.1559, -0.0553,  0.2332,\n",
       "         -0.0359,  0.2801]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 顺序块\n",
    "- $\\mathrm{Sequential}$ 类的工作：串联其他模块。\n",
    "- 自定义的 $\\mathrm{Sequential}$ 只需定义：一种将块逐个追加到列表中的函数；一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”。"
   ],
   "id": "45d6cced8715258"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:07.842908Z",
     "start_time": "2025-07-26T02:30:07.834883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import OrderedDict # 这个字典会严格记录键值对的插入顺序，遍历时也会按照这个顺序返回，这种顺序性在定义网络层的时候非常适用\n",
    "\n",
    "\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._modules = OrderedDict() # PyTorch使用_modules管理子模块\n",
    "        \n",
    "    def add(self, name, module):\n",
    "        self._modules[name] = module\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for module in self._modules.values():\n",
    "            X = module(X)\n",
    "        return X\n",
    "    \n",
    "net = MySequential()\n",
    "net.add(\"Dense1\", nn.Linear(20, 256))\n",
    "net.add(\"ReLu\", nn.ReLU())\n",
    "net.add(\"Dense2\", nn.Linear(256, 10))\n",
    "net(X)"
   ],
   "id": "cd2a8f2e5c9faaea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2800,  0.4588, -0.0936,  0.1403,  0.0847,  0.0431, -0.0910, -0.0711,\n",
       "         -0.2301,  0.1852],\n",
       "        [ 0.1910,  0.3173, -0.1902,  0.1563,  0.1460,  0.2344, -0.1021, -0.0675,\n",
       "         -0.1045,  0.0204]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 前向传播函数执行\n",
    "- 有时我们可能希望合并既不是上一层的结果也不是可更新参数的项，我们称之为常数参数（也就是有一些参数可能是指定不会更新的常量），或者需要使用Python控制流，这样就需要更灵活的前向传播函数。\n",
    "- 示例 $f(\\mathrm{x,w})=c\\cdot \\mathrm{w^Tx}$（下述示例只是展示这么一个原理流程，最后那个循环限制一般不会应用在实际任务中）："
   ],
   "id": "c66dec96fa7cc27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:09.348527Z",
     "start_time": "2025-07-26T02:30:09.296507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \"\"\"设置不会随训练更新的参数常量权重\"\"\"\n",
    "        self.register_buffer(\n",
    "            'rand_weight',\n",
    "            torch.from_numpy(np.random.uniform(size=(20, 20)).astype(np.float32))\n",
    "        )\n",
    "        self.dense = nn.Linear(20, 20)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.relu(self.dense(X))\n",
    "        \n",
    "        X = torch.relu(X @ self.rand_weight + 1) # @是PyTorch里面定义的矩阵乘法\n",
    "        \n",
    "        X = self.relu(self.dense(X))\n",
    "        \n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "            \n",
    "        return X.sum()\n",
    "    \n",
    "net = FixedHiddenMLP()\n",
    "print(net(X))"
   ],
   "id": "af0cefc7dba96002",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6320, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 混合搭配组合块：",
   "id": "cdb881e0dadddf7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:10.722358Z",
     "start_time": "2025-07-26T02:30:10.711647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(20, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.dense = nn.Linear(32, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.net(X)\n",
    "        return  self.relu(self.dense(X))\n",
    "    \n",
    "\"\"\"构建完整模型\"\"\"\n",
    "chimera = nn.Sequential(\n",
    "    NestMLP(), # 嵌套网络块\n",
    "    nn.Linear(16, 20),\n",
    "    FixedHiddenMLP() # 固定参数网络块\n",
    ")\n",
    "\n",
    "chimera(X)"
   ],
   "id": "66de05b1c263da1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5896, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 参数管理\n",
    "- 访问参数，用于调试、诊断和可视化；\n",
    "- 参数初始化；\n",
    "- 在不同模型组件间共享参数；"
   ],
   "id": "cc7e475ca85a8739"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:11.927294Z",
     "start_time": "2025-07-26T02:30:11.920783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    ")\n",
    "\n",
    "X = torch.empty(2, 4).uniform_()\n",
    "net(X)"
   ],
   "id": "c3a52592e8289d0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0856],\n",
       "        [0.1191]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 参数访问\n",
    "- 当通过 $\\mathrm{Sequential}$ 类定义模型时，我们可以通过索引来访问模型的任意层。"
   ],
   "id": "87d299f03a6160ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:13.254634Z",
     "start_time": "2025-07-26T02:30:13.249122Z"
    }
   },
   "cell_type": "code",
   "source": "print(list(net[2].parameters())) # 访问某第三层的参数",
   "id": "cb5ed7467238700a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.1565, -0.2371,  0.0991,  0.0967,  0.0907, -0.0049, -0.2985,  0.2374]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([0.1812], requires_grad=True)]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:13.919371Z",
     "start_time": "2025-07-26T02:30:13.912641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(net[0].bias)) # 访问第一层的偏置\n",
    "print(net[0].bias)\n",
    "print(net[0].bias.data)"
   ],
   "id": "b43c0c4baa87bf00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.3782, -0.0009,  0.0471, -0.0647, -0.4824,  0.4135, -0.0837,  0.3016],\n",
      "       requires_grad=True)\n",
      "tensor([-0.3782, -0.0009,  0.0471, -0.0647, -0.4824,  0.4135, -0.0837,  0.3016])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:14.646725Z",
     "start_time": "2025-07-26T02:30:14.641384Z"
    }
   },
   "cell_type": "code",
   "source": "print(net[0].weight.grad) # 由于未调用反向传播，故这里没有梯度",
   "id": "f07892205459d8bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:15.211400Z",
     "start_time": "2025-07-26T02:30:15.204466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(dict(net[0].named_parameters())) # 一次性访问所有参数（parameters()方法不包含参数名，这里这个方法包含参数名）\n",
    "print(dict(net.named_parameters()))"
   ],
   "id": "fc3fb5969e963669",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weight': Parameter containing:\n",
      "tensor([[ 0.1637,  0.0120,  0.0789,  0.2879],\n",
      "        [-0.1766,  0.0839,  0.1395,  0.4501],\n",
      "        [-0.2905,  0.4220, -0.1680,  0.4263],\n",
      "        [ 0.3222, -0.0109, -0.0829, -0.0532],\n",
      "        [ 0.1893,  0.2869, -0.4902, -0.3823],\n",
      "        [ 0.3960, -0.3771,  0.4002,  0.1650],\n",
      "        [-0.3039, -0.2589,  0.2812,  0.0850],\n",
      "        [ 0.4714, -0.2655, -0.0577, -0.3836]], requires_grad=True), 'bias': Parameter containing:\n",
      "tensor([-0.3782, -0.0009,  0.0471, -0.0647, -0.4824,  0.4135, -0.0837,  0.3016],\n",
      "       requires_grad=True)}\n",
      "{'0.weight': Parameter containing:\n",
      "tensor([[ 0.1637,  0.0120,  0.0789,  0.2879],\n",
      "        [-0.1766,  0.0839,  0.1395,  0.4501],\n",
      "        [-0.2905,  0.4220, -0.1680,  0.4263],\n",
      "        [ 0.3222, -0.0109, -0.0829, -0.0532],\n",
      "        [ 0.1893,  0.2869, -0.4902, -0.3823],\n",
      "        [ 0.3960, -0.3771,  0.4002,  0.1650],\n",
      "        [-0.3039, -0.2589,  0.2812,  0.0850],\n",
      "        [ 0.4714, -0.2655, -0.0577, -0.3836]], requires_grad=True), '0.bias': Parameter containing:\n",
      "tensor([-0.3782, -0.0009,  0.0471, -0.0647, -0.4824,  0.4135, -0.0837,  0.3016],\n",
      "       requires_grad=True), '2.weight': Parameter containing:\n",
      "tensor([[ 0.1565, -0.2371,  0.0991,  0.0967,  0.0907, -0.0049, -0.2985,  0.2374]],\n",
      "       requires_grad=True), '2.bias': Parameter containing:\n",
      "tensor([0.1812], requires_grad=True)}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:16.362275Z",
     "start_time": "2025-07-26T02:30:16.351111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"从嵌套块收集参数\"\"\"\n",
    "X = torch.empty(size=(2, 16)).uniform_()\n",
    "\n",
    "def module1():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(16, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "def module2():\n",
    "    modules = []\n",
    "    for _ in range(4):\n",
    "        modules.append(module1())\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "rgnet = nn.Sequential(\n",
    "    module2(),\n",
    "    nn.Linear(16, 10)\n",
    ")\n",
    "\n",
    "rgnet(X)"
   ],
   "id": "508afc90ad431150",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0204, -0.0319, -0.0711,  0.2111,  0.1443, -0.0613, -0.0342, -0.1088,\n",
       "         -0.1388, -0.1431],\n",
       "        [-0.0202, -0.0319, -0.0713,  0.2115,  0.1443, -0.0614, -0.0341, -0.1087,\n",
       "         -0.1384, -0.1434]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:17.073262Z",
     "start_time": "2025-07-26T02:30:17.068219Z"
    }
   },
   "cell_type": "code",
   "source": "print(rgnet.named_parameters)",
   "id": "412bb3fcfe0a7b0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=16, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 参数初始化\n",
    "- 内置初始化，$\\mathrm{PyTorch}$ 是直接内置默认初始化参数的，即像前述的一样某层网络会自行初始化参数。\n",
    "- 自定义初始化："
   ],
   "id": "27921e94956bfde1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:18.697635Z",
     "start_time": "2025-07-26T02:30:18.689638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"逐层初始化（基础）\"\"\"\n",
    "def custom_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # 均匀分布初始化 [-0.1, 0.1]\n",
    "        nn.init.uniform_(m.weight, -0.1, 0.1)\n",
    "        # 偏置初始化为1\n",
    "        nn.init.constant_(m.bias, 1.0)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(8, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 4)\n",
    ")\n",
    "\n",
    "net.apply(custom_init)"
   ],
   "id": "ec9ef29a51dda94c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=32, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:19.682260Z",
     "start_time": "2025-07-26T02:30:19.673444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(net[0].bias.data)\n",
    "print(net[0].weight.data)"
   ],
   "id": "23c8fc25d826ad18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[ 0.0845, -0.0927, -0.0051, -0.0591, -0.0818, -0.0238, -0.0574, -0.0345],\n",
      "        [ 0.0129,  0.0978,  0.0314,  0.0757, -0.0399, -0.0337,  0.0914, -0.0711],\n",
      "        [ 0.0414,  0.0297, -0.0674, -0.0019,  0.0947, -0.0402,  0.0336,  0.0106],\n",
      "        [ 0.0675,  0.0439, -0.0252, -0.0059,  0.0106,  0.0692,  0.0158, -0.0868],\n",
      "        [ 0.0024, -0.0575,  0.0993, -0.0377,  0.0840,  0.0106, -0.0862, -0.0016],\n",
      "        [-0.0972,  0.0099, -0.0154,  0.0882, -0.0650,  0.0459, -0.0416, -0.0865],\n",
      "        [ 0.0739,  0.0625, -0.0157,  0.0348, -0.0401,  0.0072, -0.0614, -0.0939],\n",
      "        [-0.0630,  0.0483, -0.0793, -0.0712,  0.0016, -0.0036,  0.0723, -0.0398],\n",
      "        [-0.0302,  0.0622, -0.0696,  0.0739, -0.0906, -0.0824,  0.0484, -0.0959],\n",
      "        [ 0.0737,  0.0826,  0.0531, -0.0345,  0.0983, -0.0931, -0.0440,  0.0517],\n",
      "        [ 0.0052,  0.0222,  0.0493, -0.0243, -0.0403,  0.0276, -0.0642, -0.0865],\n",
      "        [ 0.0564, -0.0213, -0.0220, -0.0780,  0.0421,  0.0961,  0.0622, -0.0970],\n",
      "        [-0.0912,  0.0327, -0.0752,  0.0147, -0.0536, -0.0266,  0.0519, -0.0709],\n",
      "        [ 0.0578, -0.0866,  0.0893,  0.0630, -0.0064,  0.0507, -0.0838,  0.0254],\n",
      "        [-0.0454, -0.0452, -0.0585,  0.0570, -0.0735, -0.0329, -0.0439, -0.0098],\n",
      "        [-0.0642,  0.0847, -0.0386, -0.0191,  0.0422, -0.0092,  0.0851, -0.0209],\n",
      "        [ 0.0066, -0.0905, -0.0868,  0.0844, -0.0124,  0.0382,  0.0413,  0.0694],\n",
      "        [ 0.0387, -0.0378, -0.0693,  0.0359, -0.0285,  0.0472, -0.0176,  0.0806],\n",
      "        [-0.0499,  0.0080,  0.0216,  0.0067,  0.0513, -0.0984,  0.0162,  0.0571],\n",
      "        [-0.0722,  0.0052, -0.0829,  0.0487,  0.0440, -0.0877, -0.0408, -0.0979],\n",
      "        [ 0.0703, -0.0428, -0.0233, -0.0384, -0.0662, -0.0131,  0.0967,  0.0081],\n",
      "        [ 0.0665,  0.0772,  0.0068, -0.0101, -0.0768, -0.0303,  0.0832, -0.0271],\n",
      "        [-0.0634, -0.0817, -0.0759, -0.0250, -0.0375,  0.0326, -0.0502,  0.0659],\n",
      "        [-0.0522,  0.0328,  0.0953,  0.0820,  0.0188,  0.0912,  0.0478, -0.0959],\n",
      "        [ 0.0861,  0.0444, -0.0538, -0.0512,  0.0162, -0.0733, -0.0484, -0.0621],\n",
      "        [ 0.0649,  0.0562, -0.0910,  0.0005, -0.0536,  0.0696, -0.0822, -0.0947],\n",
      "        [ 0.0536, -0.0049,  0.0826,  0.0262, -0.0665, -0.0971,  0.0380,  0.0123],\n",
      "        [-0.0988,  0.0160,  0.0113, -0.0950, -0.0863,  0.0804, -0.0191, -0.0320],\n",
      "        [ 0.0062, -0.0320,  0.0493, -0.0057,  0.0951, -0.0498,  0.0062, -0.0690],\n",
      "        [-0.0160, -0.0222,  0.0122, -0.0780,  0.0247,  0.0794,  0.0744, -0.0302],\n",
      "        [-0.0097,  0.0424, -0.0990, -0.0885,  0.0519, -0.0726, -0.0613, -0.0863],\n",
      "        [ 0.0385,  0.0877, -0.0830,  0.0669, -0.0934,  0.0087,  0.0193, -0.0473]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:20.777733Z",
     "start_time": "2025-07-26T02:30:20.770759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"直接设置参数\"\"\"\n",
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]"
   ],
   "id": "e6b98eef0b55628b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000,  0.9073,  0.9949,  0.9409,  0.9182,  0.9762,  0.9426,  0.9655])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 参数绑定\n",
    "- 多个层间共享参数："
   ],
   "id": "1301815f48aa7f50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:23.344455Z",
     "start_time": "2025-07-26T02:30:23.336390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(20, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 10),\n",
    ")\n",
    "\n",
    "\"\"\"共享参数层定义，第二层和第三层绑定\"\"\"\n",
    "shared_layer = nn.Linear(8, 8)\n",
    "net[2] = shared_layer\n",
    "net[4] = shared_layer\n",
    "\n",
    "X = torch.empty(size=(2, 20)).uniform_()\n",
    "net(X)\n",
    "\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "\"\"\"确保是对象为同一个，而不是相同值\"\"\"\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ],
   "id": "58c45f422a0fa794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 延后初始化\n",
    "- 延后初始化，即直到数据第一次通过模型传递时，框架才会动态地推断出每个层的大小。\n",
    "\n",
    "**注**：如果使用延迟初始化配合优化器的话，要注意，优化器一定要在初始化参数之后再创建。"
   ],
   "id": "ee106166d5fbaf8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:25.352442Z",
     "start_time": "2025-07-26T02:30:25.346421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"基础方法结合手动实现（再高一级的话可以使用装饰器，为任意的nn.module都添加延迟初始化方法）\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.layer = None # 通过延迟初始化Sequential来进行延迟初始化\n",
    "        \n",
    "    def forward(self, X):\n",
    "        if self.layer is None:\n",
    "            self.layer = nn.Sequential(\n",
    "                nn.Linear(X.shape[-1], 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 10)\n",
    "            ).to(X.device)\n",
    "            \n",
    "        return self.layer(X)\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "print(net.named_parameters)"
   ],
   "id": "d2026db54305ce9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of Net()>\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:26.344836Z",
     "start_time": "2025-07-26T02:30:26.332416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.empty(size=(2, 20)).uniform_()\n",
    "net(X)\n",
    "\n",
    "print(net.named_parameters)\n",
    "dict(net.named_parameters())"
   ],
   "id": "b9e8f82b078856a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of Net(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'layer.0.weight': Parameter containing:\n",
       " tensor([[ 0.1826,  0.1373,  0.1924,  ...,  0.1936,  0.0229,  0.0384],\n",
       "         [-0.0354, -0.1353,  0.0223,  ..., -0.0792, -0.0121, -0.0005],\n",
       "         [ 0.2221, -0.1461, -0.0855,  ...,  0.0832, -0.0940, -0.1745],\n",
       "         ...,\n",
       "         [ 0.0410, -0.1213,  0.1663,  ..., -0.2152,  0.0192,  0.0083],\n",
       "         [-0.2026,  0.0560, -0.1945,  ...,  0.1528,  0.1452,  0.0532],\n",
       "         [ 0.1185, -0.0963,  0.1340,  ...,  0.1784,  0.0988,  0.0216]],\n",
       "        requires_grad=True),\n",
       " 'layer.0.bias': Parameter containing:\n",
       " tensor([-0.1624, -0.1978,  0.2120,  0.1177,  0.2041, -0.0354,  0.1369,  0.0089,\n",
       "          0.1326,  0.0986,  0.1256,  0.0936, -0.2094,  0.0953,  0.2233,  0.2158,\n",
       "         -0.0699, -0.2023,  0.1430,  0.1504, -0.0834,  0.0375,  0.1569,  0.0692,\n",
       "          0.1154, -0.1165,  0.1314,  0.1882,  0.1652, -0.0318,  0.0725, -0.1844,\n",
       "          0.0741,  0.0400, -0.1162, -0.1224, -0.1405,  0.0018,  0.1389, -0.1001,\n",
       "          0.0668, -0.1692, -0.1461,  0.0586,  0.1048,  0.0057, -0.1768, -0.1521,\n",
       "         -0.0759,  0.0486,  0.0609,  0.1732, -0.0058, -0.1786, -0.1519,  0.1900,\n",
       "          0.0986, -0.1892, -0.1799, -0.0125,  0.0072,  0.2112, -0.2158, -0.1717,\n",
       "         -0.1217,  0.1877, -0.0130, -0.0487,  0.0118,  0.1440,  0.1451,  0.1972,\n",
       "          0.2026, -0.2119,  0.0303,  0.1508, -0.0274,  0.0366, -0.1847,  0.0435,\n",
       "         -0.1660, -0.0956, -0.2030, -0.0589,  0.1149, -0.1460,  0.1089,  0.0842,\n",
       "         -0.0004,  0.1884,  0.0340, -0.2173, -0.0029,  0.2148, -0.2212,  0.1891,\n",
       "         -0.0360, -0.0838,  0.1664, -0.0207, -0.1204,  0.2097, -0.0691,  0.0726,\n",
       "         -0.2066,  0.0995,  0.0340,  0.0952,  0.0676, -0.1233, -0.0983, -0.1634,\n",
       "          0.0412,  0.0180, -0.0871, -0.0953, -0.2002, -0.1290,  0.0526,  0.2186,\n",
       "          0.1503,  0.1024,  0.0041,  0.1432,  0.1238, -0.0507,  0.0248,  0.1750,\n",
       "          0.0573, -0.0995,  0.1444,  0.1824, -0.0486, -0.0705,  0.1350, -0.1366,\n",
       "         -0.2180, -0.0674,  0.1793,  0.1716,  0.0140,  0.0455,  0.0571,  0.0357,\n",
       "         -0.1283,  0.1304,  0.1940,  0.1314, -0.0370, -0.1615,  0.1061,  0.0348,\n",
       "          0.1155, -0.1442,  0.1201, -0.0049, -0.0607, -0.1602, -0.1495, -0.1917,\n",
       "          0.0844,  0.2009,  0.0908,  0.2001, -0.1448, -0.1207,  0.1206, -0.1275,\n",
       "         -0.2113,  0.0158,  0.1169,  0.1896,  0.0533,  0.0425, -0.0039,  0.1724,\n",
       "         -0.0858, -0.1922,  0.1827, -0.0307,  0.1448,  0.0578, -0.0578,  0.0240,\n",
       "          0.1923,  0.1046,  0.1024,  0.1213,  0.0406,  0.0850,  0.0242, -0.1002,\n",
       "         -0.2201, -0.0015,  0.0861,  0.1552,  0.2186, -0.1787,  0.1341,  0.0766,\n",
       "         -0.1655,  0.1668,  0.1702,  0.1150,  0.1398,  0.1771,  0.0384,  0.1486,\n",
       "          0.1776, -0.2157,  0.0554,  0.0667,  0.0307, -0.2031, -0.0603, -0.1601,\n",
       "         -0.1167,  0.1179, -0.1183,  0.0291, -0.1238,  0.1601, -0.1412, -0.0853,\n",
       "          0.1106, -0.0254, -0.0990, -0.1256, -0.0323, -0.1083, -0.0488, -0.0291,\n",
       "         -0.0194,  0.0196, -0.1593, -0.1213, -0.1455, -0.1067, -0.0995,  0.2051,\n",
       "          0.2063, -0.0628,  0.1612,  0.0946,  0.0546, -0.1684, -0.1103, -0.1375,\n",
       "         -0.1612,  0.1398, -0.0348,  0.0741, -0.0012, -0.0152, -0.1385, -0.0452],\n",
       "        requires_grad=True),\n",
       " 'layer.2.weight': Parameter containing:\n",
       " tensor([[-0.0306, -0.0299, -0.0468,  ..., -0.0039, -0.0595,  0.0414],\n",
       "         [-0.0193,  0.0084,  0.0057,  ..., -0.0495,  0.0050, -0.0135],\n",
       "         [ 0.0095,  0.0161, -0.0358,  ..., -0.0506, -0.0122, -0.0152],\n",
       "         ...,\n",
       "         [-0.0074,  0.0113,  0.0505,  ...,  0.0472,  0.0178, -0.0518],\n",
       "         [ 0.0142,  0.0113, -0.0291,  ...,  0.0382,  0.0342, -0.0312],\n",
       "         [ 0.0397,  0.0478,  0.0543,  ...,  0.0226, -0.0517,  0.0069]],\n",
       "        requires_grad=True),\n",
       " 'layer.2.bias': Parameter containing:\n",
       " tensor([-0.0531,  0.0225,  0.0167, -0.0545, -0.0207, -0.0304, -0.0205, -0.0136,\n",
       "         -0.0373,  0.0385], requires_grad=True)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 自定义层\n",
    "### 不带参数的层\n",
    "- 要构建不带参数的层，我们只需继承基础层类并实现前向传播功能即可："
   ],
   "id": "b980c32ebcb0559a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:28.249548Z",
     "start_time": "2025-07-26T02:30:28.242414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    @staticmethod\n",
    "    def forward(X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "layer = CenteredLayer()\n",
    "layer(np.array([1, 2, 3, 4, 5]))"
   ],
   "id": "5a77f5b611220ecd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:28.856713Z",
     "start_time": "2025-07-26T02:30:28.848969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(8, 128),\n",
    "    CenteredLayer()\n",
    ")\n",
    "\n",
    "Y = net(torch.empty(size=(4, 8)).uniform_())\n",
    "Y.mean()"
   ],
   "id": "cdfe6dc9ec12a4ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6566e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 带参数的层",
   "id": "30c53bca1ac61d64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:30.011158Z",
     "start_time": "2025-07-26T02:30:30.003797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyDense(nn.Module):\n",
    "    def __init__(self, units, in_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.Tensor(units))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight) + self.bias\n",
    "        return nn.functional.relu(linear)\n",
    "    \n",
    "dense = MyDense(units=3, in_units=5)\n",
    "dict(dense.named_parameters())"
   ],
   "id": "4b711e9d40217620",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': Parameter containing:\n",
       " tensor([[ 1.1049e+16,  1.4419e-42,  7.8869e-02],\n",
       "         [ 2.8788e-01, -1.7655e-01,  8.3899e-02],\n",
       "         [ 1.3952e-01,  4.5010e-01, -2.9045e-01],\n",
       "         [ 4.2198e-01, -1.6805e-01,  4.2626e-01],\n",
       "         [ 3.2222e-01, -1.0867e-02, -8.2945e-02]], requires_grad=True),\n",
       " 'bias': Parameter containing:\n",
       " tensor([2.3048e-03, 1.8980e+01, 0.0000e+00], requires_grad=True)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:30.638342Z",
     "start_time": "2025-07-26T02:30:30.630330Z"
    }
   },
   "cell_type": "code",
   "source": "dense(torch.empty(size=(2, 5)).uniform_())",
   "id": "49ecc98282a0eaea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1787e+15, 1.9171e+01, 2.5464e-02],\n",
       "        [8.2646e+14, 1.9052e+01, 1.7230e-01]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:30:31.187344Z",
     "start_time": "2025-07-26T02:30:31.180826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = nn.Sequential(\n",
    "    MyDense(8, in_units=64),\n",
    "    MyDense(1, in_units=8)\n",
    ")\n",
    "net(torch.empty(size=(2, 64)).uniform_())"
   ],
   "id": "f7c950d6c413042c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1329e+16],\n",
       "        [1.1344e+16]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 读写文件\n",
    "### 加载保存张量\n",
    "- $\\mathrm{PyTorch}$ 在保存张量的的时候可以保留设备信息（加载时会自动恢复到原设备），可保存计算图、模型结构、梯度、设备信息，但是 $\\mathrm{NumPy}$ 不行"
   ],
   "id": "982d5051037eba6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T02:49:48.262213Z",
     "start_time": "2025-07-26T02:49:48.248830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = np.arange(4)\n",
    "torch.save(x, 'x-file.pt')"
   ],
   "id": "965aaeb617eed57b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:10:05.312919Z",
     "start_time": "2025-07-26T03:10:05.306749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x2 = torch.load('x-file.pt', weights_only=False) # 默认为True文件里有些对象会加载不出来\n",
    "x2"
   ],
   "id": "e2fa6ad2f3909ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:38:11.979993Z",
     "start_time": "2025-07-26T03:38:11.971349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = np.zeros(4)\n",
    "torch.save([x, y], 'x-file.pt')\n",
    "x2, y2 = torch.load('x-file.pt', weights_only=False)\n",
    "(x2, y2)"
   ],
   "id": "f460b2e482fe48f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T03:48:48.784621Z",
     "start_time": "2025-07-26T03:48:48.776987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict.pt')\n",
    "mydict2 = torch.load('mydict.pt', weights_only=False)\n",
    "mydict2"
   ],
   "id": "1e59b04258de1fa5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([0, 1, 2, 3]), 'y': array([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 加载保存模型参数",
   "id": "115b71b5b01b3e12"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:35:34.262825Z",
     "start_time": "2025-07-26T04:35:34.254853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = nn.functional.relu(self.hidden(X))\n",
    "        return self.output(X)\n",
    "    \n",
    "net = MLP()\n",
    "X = torch.empty(size=(2, 20)).uniform_()\n",
    "Y = net(X)  "
   ],
   "id": "d1089b2a4b5d5b0",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T05:25:45.765049Z",
     "start_time": "2025-07-26T05:25:45.756668Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(net.state_dict(), 'mlp.pth')",
   "id": "d538d8e5a220464f",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T05:46:08.890971Z",
     "start_time": "2025-07-26T05:46:08.877423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.pth'))"
   ],
   "id": "71987ce76cba1226",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T05:46:44.511832Z",
     "start_time": "2025-07-26T05:46:44.505624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ],
   "id": "be228a644d687147",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## $\\mathrm{GPU}$ 加速训练",
   "id": "85e0f818ddc54431"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:00:43.016226Z",
     "start_time": "2025-07-26T06:00:43.011099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "cpu_device = torch.device('cpu')\n",
    "gpu_device_0 = torch.device('cuda:0')\n",
    "gpu_device_1 = torch.device('cuda:1')"
   ],
   "id": "188dd1d4d2fe4b56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " device(type='cpu'),\n",
       " device(type='cuda', index=1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:01:48.077015Z",
     "start_time": "2025-07-26T06:01:48.070855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.to(cpu_device), tensor.to(gpu_device_0)"
   ],
   "id": "b4e1f9cae324750c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([1, 2, 3], device='cuda:0'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:03:33.377368Z",
     "start_time": "2025-07-26T06:03:33.369314Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.device_count()",
   "id": "1be11512e0e4b858",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:04:12.740943Z",
     "start_time": "2025-07-26T06:04:12.735435Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.get_device_name()",
   "id": "3892db400dd58506",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1650'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 张量与 $\\mathrm{GPU}$",
   "id": "42d26305341bfb68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:13:17.705530Z",
     "start_time": "2025-07-26T06:13:17.700029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "print(x.device)"
   ],
   "id": "95d67edfb85586f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:14:17.575177Z",
     "start_time": "2025-07-26T06:14:17.567402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.ones((2,3), device='cuda:0')\n",
    "X"
   ],
   "id": "946d58e765f4f0e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 关于张量的复制或者计算，需要保证操作的张量都在通过一个设备下（都在 $\\mathrm{CPU}$ 或者同一个 $\\mathrm{GPU}$）",
   "id": "c1405024238d8166"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:18:22.090250Z",
     "start_time": "2025-07-26T06:18:22.062596Z"
    }
   },
   "cell_type": "code",
   "source": "x.to('cuda:0') + X",
   "id": "9deee9355eb0e6d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [2., 3., 4.]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 神经网络与 $\\mathrm{GPU}$",
   "id": "32804c696e617966"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:27:05.608162Z",
     "start_time": "2025-07-26T06:27:05.592133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(3, 1),\n",
    "    nn.ReLU()\n",
    ")\n",
    "net.to(device)\n",
    "net(X)"
   ],
   "id": "194b973d5c91632a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9704],\n",
       "        [0.9704]], device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T06:31:52.463635Z",
     "start_time": "2025-07-26T06:31:52.457303Z"
    }
   },
   "cell_type": "code",
   "source": "net[0].weight.device",
   "id": "618e940036d1da9f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "73c768cd2a7c5c34"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
